{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM2-LoRA å®šå‘è¿›åŒ–å·¥ä½œæµï¼šåŸºäº Gibbs é‡‡æ ·çš„åºåˆ—æ¼‚ç§»\n",
    "\n",
    "æœ¬ Notebook å®ç°äº†**â€œç”Ÿæˆå¼â€**çš„è›‹ç™½æ”¹é€ ç­–ç•¥ï¼ˆStrategy 1: In silico Sequence Driftï¼‰ã€‚\n",
    "\n",
    "**æ ¸å¿ƒåŸç†**ï¼š\n",
    "åˆ©ç”¨å¾®è°ƒåçš„ LoRA æ¨¡å‹ï¼ˆå·²ä¹ å¾—å—œçƒ­/è€ç¢±ç­‰ç‰¹æ€§ï¼‰ï¼Œå¯¹é‡ç”Ÿå‹è›‹ç™½è¿›è¡Œ**è¿­ä»£å¼æ©ç é‡æ„ (Iterative Masking & Refilling)**ã€‚\n",
    "è¿™ç±»ä¼¼äºåœ¨è®¡ç®—æœºä¸­æ¨¡æ‹Ÿè‡ªç„¶ç•Œçš„â€œéšæœºçªå˜-é€‰æ‹©â€è¿‡ç¨‹ï¼Œä½†è¿™é‡Œçš„â€œé€‰æ‹©â€æ˜¯ç”± ESM2 æ¨¡å‹æ ¹æ®å…¶å­¦åˆ°çš„è¿›åŒ–æ¦‚ç‡å®Œæˆçš„ã€‚\n",
    "\n",
    "**é€‚ç”¨åœºæ™¯**ï¼š\n",
    "1. å¯»æ‰¾æ·±åº¦çš„ç»„åˆçªå˜ï¼ˆä¸ä»…æ˜¯å•ç‚¹ï¼‰ã€‚\n",
    "2. æ¢ç´¢åºåˆ—çš„â€œéšç©ºé—´â€ï¼Œè®©è›‹ç™½åœ¨ä¿æŒæ ¸å¿ƒç»“æ„çš„åŒæ—¶â€œæ¼‚ç§»â€å‘æ›´ç¨³å®šçš„çŠ¶æ€ã€‚\n",
    "3. ä¸ºæ„å»ºçªå˜åº“æä¾›é«˜æ½œåŠ›çš„å€™é€‰åºåˆ—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# è®¾ç½® HuggingFace é•œåƒ\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, EsmForMaskedLM\n",
    "from peft import PeftModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. å…¨å±€å‚æ•°è®¾ç½® (User Configuration)\n",
    "**è¯·åœ¨æ­¤å¤„è®¾ç½®æ‚¨çš„æ¨¡å‹è·¯å¾„å’Œç›®æ ‡è›‹ç™½åºåˆ—ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= æ¨¡å‹è·¯å¾„ =================\n",
    "# åŸºç¡€æ¨¡å‹ (é€šå¸¸ä¸ç”¨æ”¹)\n",
    "BASE_MODEL_NAME = \"facebook/esm2_t33_650M_UR50D\"\n",
    "\n",
    "# æ‚¨çš„ LoRA æ¨¡å‹è·¯å¾„ (è®­ç»ƒè¾“å‡ºçš„ final_model æ–‡ä»¶å¤¹è·¯å¾„)\n",
    "# ç¤ºä¾‹: \"./esm2_lora_output/final_model\"\n",
    "LORA_MODEL_PATH = \"/esm2_lora_ph5.0_less/final_model\"\n",
    "\n",
    "# ================= ç›®æ ‡è›‹ç™½ =================\n",
    "# å¾…æ”¹é€ çš„é‡ç”Ÿå‹åºåˆ— (Wild Type)\n",
    "TARGET_SEQUENCE = \"SLKD\"\n",
    "\n",
    "# ================= è¿›åŒ–å‚æ•° (å…³é”®) =================\n",
    "# 1. è¿›åŒ–è½®æ•° (Steps): å»ºè®® 50-200ã€‚è½®æ•°è¶Šå¤šï¼Œåºåˆ—æ”¹å˜è¶Šå¤§ã€‚\n",
    "NUM_STEPS = 50\n",
    "\n",
    "# 2. æ©ç æ¯”ä¾‹ (Mask Ratio): æ¯æ¬¡è¿­ä»£éšæœºé®æŒ¡å¤šå°‘æ¯”ä¾‹çš„æ°¨åŸºé…¸ã€‚å»ºè®® 0.1 - 0.15ã€‚\n",
    "# 0.1 æ„å‘³ç€æ¯æ¬¡æ”¹åŠ¨è¾ƒæ¸©å’Œï¼Œ0.2 æ„å‘³ç€å‰§çƒˆå˜åŠ¨ã€‚\n",
    "MASK_RATIO = 0.2\n",
    "\n",
    "# 3. é‡‡æ ·å¤šæ ·æ€§ (Top-K): æ¯æ¬¡å¡«ç©ºæ—¶ï¼Œä»æ¦‚ç‡æœ€é«˜çš„ K ä¸ªæ°¨åŸºé…¸é‡ŒæŠ½ç­¾ã€‚\n",
    "# K=1: è´ªå©ªæ¨¡å¼ (æ€»æ˜¯é€‰æ¦‚ç‡æœ€å¤§çš„ï¼Œç»“æœæœ€ç¨³å®šä½†æœ€ä¿å®ˆ)ã€‚\n",
    "# K=5: æ¨èå€¼ (å…è®¸ä¸€å®šéšæœºæ€§ï¼Œèƒ½å‘ç°æ–°é¢–çªå˜)ã€‚\n",
    "TOP_K = 5\n",
    "\n",
    "# 4. å¹¶è¡Œé“¾æ•° (Parallel Chains): åŒæ—¶æ¨¡æ‹Ÿå‡ æ¡ç‹¬ç«‹çš„è¿›åŒ–è·¯å¾„ï¼Ÿ\n",
    "# å»ºè®® 3-5 æ¡ï¼Œæ–¹ä¾¿å¯¹æ¯”ä¸åŒè·¯å¾„äº§ç”Ÿçš„çªå˜ã€‚\n",
    "NUM_CHAINS = 500\n",
    "BATCH_SIZE = 64 # æ¯æ¬¡å¤„ç†çš„é“¾æ•°ï¼Œå»ºè®®æ ¹æ®æ˜¾å­˜è°ƒæ•´\n",
    "\n",
    "# 5. å›ºå®šä½ç‚¹ (Optional): å¦‚æœæŸäº›ä½ç‚¹ç»å¯¹ä¸èƒ½åŠ¨ï¼ˆå¦‚å‚¬åŒ–ä¸­å¿ƒï¼‰ï¼Œè¯·å¡«å…¥åˆ—è¡¨ (1-based)ã€‚\n",
    "# ç¤ºä¾‹: FROZEN_POSITIONS = [10, 11, 12]  (è¡¨ç¤ºç¬¬10,11,12ä½ä¿æŒä¸å˜)\n",
    "FROZEN_POSITIONS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. æ¨¡å‹åŠ è½½\n",
    "è‡ªåŠ¨åŠ è½½åŸºç¡€æ¨¡å‹å¹¶æŒ‚è½½æ‚¨çš„ LoRA é€‚é…å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­£åœ¨ä½¿ç”¨è®¡ç®—è®¾å¤‡: mps\n",
      "â³ æ­£åœ¨åŠ è½½ Tokenizer...\n",
      "â³ æ­£åœ¨åŠ è½½åŸºç¡€ ESM2 æ¨¡å‹ (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...\n",
      "ğŸ”„ æ­£åœ¨æŒ‚è½½ LoRA é€‚é…å™¨: /Users/zhanghaonan/Documents/ML/protein_galaxy/esm2_lora/esm2_lora_ph5.0_less/final_model ...\n",
      "âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼Œè¿›åŒ–å¼•æ“å·²å°±ç»ªã€‚\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"ğŸš€ æ­£åœ¨ä½¿ç”¨è®¡ç®—è®¾å¤‡: {device}\")\n",
    "\n",
    "# åŠ è½½ Tokenizer\n",
    "print(\"â³ æ­£åœ¨åŠ è½½ Tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "# åŠ è½½åŸºç¡€æ¨¡å‹\n",
    "print(\"â³ æ­£åœ¨åŠ è½½åŸºç¡€ ESM2 æ¨¡å‹ (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...\")\n",
    "base_model = EsmForMaskedLM.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "# æŒ‚è½½ LoRA\n",
    "print(f\"ğŸ”„ æ­£åœ¨æŒ‚è½½ LoRA é€‚é…å™¨: {LORA_MODEL_PATH} ...\")\n",
    "model = PeftModel.from_pretrained(base_model, LORA_MODEL_PATH)\n",
    "model.to(device)\n",
    "model.eval() # å¼€å¯æ¨ç†æ¨¡å¼\n",
    "\n",
    "# ğŸš€ åªæœ‰åœ¨ NVIDIA GPU (Linux) ä¸Šæ‰å¼€å¯è¿™ä¸ª\n",
    "if torch.cuda.is_available():\n",
    "    print(\"ğŸ”¥ æ£€æµ‹åˆ° NVIDIA GPUï¼Œæ­£åœ¨å¯ç”¨ torch.compile ç¼–è¯‘åŠ é€Ÿ...\")\n",
    "    try:\n",
    "        # è¿™ä¼šè®©ç¬¬ä¸€æ¬¡è¿è¡Œç¨å¾®æ…¢ä¸€ç‚¹ï¼ˆç¼–è¯‘ï¼‰ï¼Œä½†ä¹‹åçš„ 500 æ­¥å¾ªç¯ä¼šé£å¿«\n",
    "        model = torch.compile(model) \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ç¼–è¯‘å¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šæ¨¡å¼: {e}\")\n",
    "\n",
    "print(\"âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼Œè¿›åŒ–å¼•æ“å·²å°±ç»ªã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. å®šä¹‰ Gibbs é‡‡æ ·è¿›åŒ–å‡½æ•°\n",
    "è¿™æ˜¯æ ¸å¿ƒç®—æ³•éƒ¨åˆ†ã€‚å®ƒæ‰§è¡Œâ€œé®æŒ¡ -> é¢„æµ‹ -> é‡‡æ · -> æ›´æ–°â€çš„å¾ªç¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_batch_tensor_optimized(start_seq, num_chains, num_steps, patience=10):\n",
    "    \"\"\"\n",
    "    æè‡´ä¼˜åŒ–ç‰ˆï¼šåŒ…å« Early Stopping å’Œ inference_mode\n",
    "    patience: å¦‚æœåºåˆ—è¿ç»­å¤šå°‘æ­¥æ²¡æœ‰é‡‡çº³æ–°çªå˜(æˆ–å˜åŒ–æå°)ï¼Œåˆ™è®¤ä¸ºæ”¶æ•›\n",
    "    \"\"\"\n",
    "    # å¼ºåˆ¶ä½¿ç”¨ inference_mode (æ¯” no_grad æ›´å¿«ä¸€ç‚¹ç‚¹)\n",
    "    # å¼ºåˆ¶ FP16\n",
    "    initial_inputs = tokenizer(start_seq, return_tensors=\"pt\").to(device)\n",
    "    input_ids_base = initial_inputs[\"input_ids\"]\n",
    "    seq_len = len(start_seq)\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "    \n",
    "    final_sequences = []\n",
    "    \n",
    "    # åŠ¨æ€è°ƒæ•´ Batch Size (M4 32G å»ºè®® 64-100ï¼Œå¦‚æœ 200 æ…¢å¯èƒ½æ˜¯å†…å­˜äº¤æ¢å¯¼è‡´ï¼Œå»ºè®®è®¾ä¸º 64)\n",
    "    OPTIMAL_BATCH_SIZE = BATCH_SIZE\n",
    "    num_batches = (num_chains + OPTIMAL_BATCH_SIZE - 1) // OPTIMAL_BATCH_SIZE\n",
    "    \n",
    "    print(f\"ğŸš€ æé€Ÿè¿›åŒ–æ¨¡å¼: Steps={num_steps} | Batch={OPTIMAL_BATCH_SIZE}\")\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        current_batch_size = min(OPTIMAL_BATCH_SIZE, num_chains - batch_idx * OPTIMAL_BATCH_SIZE)\n",
    "        \n",
    "        # [Batch, Length]\n",
    "        current_input_ids = input_ids_base.repeat(current_batch_size, 1)\n",
    "        \n",
    "        # ç”¨äº Early Stopping çš„è®°å½•\n",
    "        # è®°å½•ä¸Šä¸€æ­¥çš„åºåˆ—ï¼Œç”¨äºå¯¹æ¯”\n",
    "        prev_input_ids = current_input_ids.clone()\n",
    "        no_change_counter = torch.zeros(current_batch_size, device=device)\n",
    "        \n",
    "        # å¼€å¯ inference_mode \n",
    "        with torch.inference_mode(): \n",
    "            for step in tqdm(range(num_steps), desc=f\"Batch {batch_idx+1}/{num_batches}\", leave=False):\n",
    "                \n",
    "                # --- 1. ç”Ÿæˆ Mask (å¢åŠ äº†ä¿æŠ¤æœºåˆ¶ï¼Œé¿å… Mask å¤ªå¤šå¯¼è‡´å´©å) ---\n",
    "                # åŠ¨æ€ Mask æ¯”ä¾‹ï¼šéšç€æ­¥æ•°å¢åŠ ï¼ŒMask æ¯”ä¾‹é€æ¸é™ä½ï¼ˆæ¨¡æ‹Ÿé€€ç«ï¼‰\n",
    "                # å‰ 50% æ­¥æ•°ç”¨é«˜ Mask (0.2)ï¼Œå 50% ç”¨ä½ Mask (0.1) ç²¾ä¿®\n",
    "                current_mask_ratio = MASK_RATIO if step < num_steps * 0.5 else MASK_RATIO * 0.5\n",
    "                \n",
    "                rand_matrix = torch.rand(current_input_ids.shape, device=device)\n",
    "                mask_bool = rand_matrix < current_mask_ratio\n",
    "                mask_bool[:, 0] = False; mask_bool[:, -1] = False # ä¿æŠ¤ CLS/EOS\n",
    "                \n",
    "                # ä¿æŠ¤å›ºå®šä½ç‚¹\n",
    "                if FROZEN_POSITIONS:\n",
    "                    for pos in FROZEN_POSITIONS:\n",
    "                        mask_bool[:, pos] = False\n",
    "                \n",
    "                masked_input_ids = current_input_ids.clone()\n",
    "                masked_input_ids[mask_bool] = mask_token_id\n",
    "                \n",
    "                # --- 2. æ¨ç† ---\n",
    "                logits = model(input_ids=masked_input_ids).logits\n",
    "                \n",
    "                # --- 3. é‡‡æ · ---\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                top_k_probs, top_k_ids = torch.topk(probs, TOP_K)\n",
    "                top_k_probs = top_k_probs / torch.sum(top_k_probs, dim=-1, keepdim=True)\n",
    "                \n",
    "                # å±•å¹³é‡‡æ ·\n",
    "                flat_probs = top_k_probs.view(-1, TOP_K)\n",
    "                flat_ids = top_k_ids.view(-1, TOP_K)\n",
    "                sampled_indices = torch.multinomial(flat_probs, 1)\n",
    "                sampled_token_ids = torch.gather(flat_ids, 1, sampled_indices).view(current_batch_size, -1)\n",
    "                \n",
    "                # --- 4. æ›´æ–° ---\n",
    "                current_input_ids = torch.where(mask_bool, sampled_token_ids, current_input_ids)\n",
    "                \n",
    "                # --- 5. Early Stopping æ£€æŸ¥ (å¯é€‰ä¼˜åŒ–) ---\n",
    "                # æ£€æŸ¥å“ªäº›åºåˆ—è¿™ä¸€æ­¥å®Œå…¨æ²¡å˜ (æˆ–è€…å˜å›å»äº†)\n",
    "                # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†é€Ÿåº¦ï¼Œæ¯ 10 æ­¥æ£€æŸ¥ä¸€æ¬¡\n",
    "                if step % 10 == 0:\n",
    "                    is_same = torch.all(current_input_ids == prev_input_ids, dim=1)\n",
    "                    no_change_counter[is_same] += 1\n",
    "                    no_change_counter[~is_same] = 0 # é‡ç½®\n",
    "                    prev_input_ids = current_input_ids.clone()\n",
    "                    \n",
    "                    # å¦‚æœæ‰€æœ‰åºåˆ—éƒ½è¿ç»­ 5 æ¬¡æ£€æµ‹(50æ­¥)æ²¡å˜åŒ–ï¼Œæå‰ç»“æŸå½“å‰ Batch\n",
    "                    if torch.all(no_change_counter >= 5):\n",
    "                        tqdm.write(f\"  âš¡ï¸ Batch {batch_idx+1} åœ¨ Step {step} æå‰æ”¶æ•›ï¼Œè·³è¿‡åç»­æ­¥éª¤ã€‚\")\n",
    "                        break\n",
    "\n",
    "        # è§£ç \n",
    "        for i in range(current_batch_size):\n",
    "            seq_str = tokenizer.decode(current_input_ids[i], skip_special_tokens=True).replace(\" \", \"\")\n",
    "            final_sequences.append(seq_str)\n",
    "            \n",
    "    return final_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. è¿è¡Œè¿›åŒ–\n",
    "æ ¹æ®è®¾ç½®çš„ `NUM_CHAINS` å¯åŠ¨å¤šæ¡å¹¶è¡Œè¿›åŒ–é“¾ï¼Œç”Ÿæˆä¸åŒçš„å€™é€‰åºåˆ—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ï¸ æ¨¡å‹å·²è½¬æ¢ä¸º FP16 åŠç²¾åº¦æ¨¡å¼\n",
      "ğŸš€ æé€Ÿè¿›åŒ–æ¨¡å¼: Steps=50 | Batch=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å®Œæˆï¼å…±ç”Ÿæˆ 500 æ¡åºåˆ—ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# ç¡®ä¿ä½¿ç”¨åŠç²¾åº¦ (Float16) ä»¥èŠ‚çœæ˜¾å­˜å¹¶åŠ é€Ÿ (M4 MPS æ”¯æŒè‰¯å¥½)\n",
    "# æ³¨æ„ï¼šå¦‚æœä¹‹å‰åŠ è½½æ¨¡å‹æ²¡ç”¨åŠç²¾åº¦ï¼Œè¿™é‡Œè½¬æ¢ä¸€ä¸‹\n",
    "model.half() \n",
    "print(\"âš¡ï¸ æ¨¡å‹å·²è½¬æ¢ä¸º FP16 åŠç²¾åº¦æ¨¡å¼\")\n",
    "\n",
    "# è¿è¡Œå¹¶è¡Œè¿›åŒ–\n",
    "# è¿™é‡Œç›´æ¥ç”Ÿæˆæ‰€æœ‰é“¾\n",
    "evolved_sequences = evolve_batch_tensor_optimized(\n",
    "    start_seq=TARGET_SEQUENCE, \n",
    "    num_chains=NUM_CHAINS,  # 1000\n",
    "    num_steps=NUM_STEPS     # 500\n",
    ")\n",
    "\n",
    "print(f\"âœ… å®Œæˆï¼å…±ç”Ÿæˆ {len(evolved_sequences)} æ¡åºåˆ—ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ç»“æœåˆ†æä¸å¯è§†åŒ–\n",
    "å¯¹æ¯”é‡ç”Ÿå‹ (WT) å’Œç”Ÿæˆçš„å˜ä½“ï¼Œæå–å…·ä½“çš„çªå˜ä½ç‚¹ (ä¾‹å¦‚ `A26R`)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š è¿›åŒ–ç»“æœæ±‡æ€»:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chain_ID</th>\n",
       "      <th>Mutation_Count</th>\n",
       "      <th>Mutations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>V1M, D2E, N3D, K4E, F5I, N6K, K7E, E8L, Q9I, Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>V1M, D2S, N3E, F5I, N6D, K7P, Q9I, Q10R, N11E,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>V1M, D2E, N3E, K4E, F5L, N6E, K7E, Q9L, Q10E, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>V1M, D2T, N3K, F5Q, N6K, K7E, Q9M, Q10K, N11K,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>V1M, N3K, K4E, F5N, N6L, K7I, E8N, Q9K, Q10L, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>52</td>\n",
       "      <td>V1M, D2E, N3L, F5L, N6K, K7E, E8K, Q9L, Q10L, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>50</td>\n",
       "      <td>V1M, D2A, N3D, K4D, F5A, N6D, K7A, E8A, Q9S, Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>55</td>\n",
       "      <td>V1M, D2T, N3D, K4T, F5P, N6P, K7D, E8D, Q9P, Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>52</td>\n",
       "      <td>V1M, D2K, N3K, F5I, N6K, E8I, Q9K, Q10I, N11E,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>49</td>\n",
       "      <td>V1M, N3L, K4N, F5E, N6I, K7L, E8D, Q9S, Q10L, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chain_ID  Mutation_Count  \\\n",
       "0           1              51   \n",
       "1           2              51   \n",
       "2           3              52   \n",
       "3           4              51   \n",
       "4           5              49   \n",
       "..        ...             ...   \n",
       "495       496              52   \n",
       "496       497              50   \n",
       "497       498              55   \n",
       "498       499              52   \n",
       "499       500              49   \n",
       "\n",
       "                                             Mutations  \n",
       "0    V1M, D2E, N3D, K4E, F5I, N6K, K7E, E8L, Q9I, Q...  \n",
       "1    V1M, D2S, N3E, F5I, N6D, K7P, Q9I, Q10R, N11E,...  \n",
       "2    V1M, D2E, N3E, K4E, F5L, N6E, K7E, Q9L, Q10E, ...  \n",
       "3    V1M, D2T, N3K, F5Q, N6K, K7E, Q9M, Q10K, N11K,...  \n",
       "4    V1M, N3K, K4E, F5N, N6L, K7I, E8N, Q9K, Q10L, ...  \n",
       "..                                                 ...  \n",
       "495  V1M, D2E, N3L, F5L, N6K, K7E, E8K, Q9L, Q10L, ...  \n",
       "496  V1M, D2A, N3D, K4D, F5A, N6D, K7A, E8A, Q9S, Q...  \n",
       "497  V1M, D2T, N3D, K4T, F5P, N6P, K7D, E8D, Q9P, Q...  \n",
       "498  V1M, D2K, N3K, F5I, N6K, E8I, Q9K, Q10I, N11E,...  \n",
       "499  V1M, N3L, K4N, F5E, N6I, K7L, E8D, Q9S, Q10L, ...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ [Hotspots] å‡ºç°é¢‘ç‡æœ€é«˜çš„çªå˜ (å…±è¯†çªå˜):\n",
      "   V1M: å‡ºç° 425/500 æ¬¡\n",
      "   P57K: å‡ºç° 180/500 æ¬¡\n",
      "   N3K: å‡ºç° 165/500 æ¬¡\n",
      "   A42K: å‡ºç° 158/500 æ¬¡\n",
      "   A29K: å‡ºç° 152/500 æ¬¡\n",
      "   A46E: å‡ºç° 152/500 æ¬¡\n",
      "   A56K: å‡ºç° 152/500 æ¬¡\n",
      "   E8K: å‡ºç° 151/500 æ¬¡\n",
      "   N28E: å‡ºç° 148/500 æ¬¡\n",
      "   D53K: å‡ºç° 148/500 æ¬¡\n"
     ]
    }
   ],
   "source": [
    "def compare_sequences(wt, mut_seq):\n",
    "    \"\"\"æ¯”è¾ƒä¸¤æ¡åºåˆ—ï¼Œè¿”å›çªå˜åˆ—è¡¨\"\"\"\n",
    "    mutations = []\n",
    "    for i, (aa1, aa2) in enumerate(zip(wt, mut_seq)):\n",
    "        if aa1 != aa2:\n",
    "            # æ ¼å¼: é‡ç”Ÿå‹ + ä½ç½®(1-based) + çªå˜å‹\n",
    "            mutations.append(f\"{aa1}{i+1}{aa2}\")\n",
    "    return mutations\n",
    "\n",
    "# æ±‡æ€»ç»“æœ\n",
    "results_data = []\n",
    "\n",
    "for i, seq in enumerate(evolved_sequences):\n",
    "    muts = compare_sequences(TARGET_SEQUENCE, seq)\n",
    "    results_data.append({\n",
    "        \"Chain_ID\": i + 1,\n",
    "        \"Mutation_Count\": len(muts),\n",
    "        \"Mutations\": \", \".join(muts),\n",
    "        \"Full_Sequence\": seq\n",
    "    })\n",
    "\n",
    "# è½¬æ¢ä¸º DataFrame å±•ç¤º\n",
    "df_results = pd.DataFrame(results_data)\n",
    "\n",
    "print(\"\\nğŸ“Š è¿›åŒ–ç»“æœæ±‡æ€»:\")\n",
    "display(df_results[[ \"Chain_ID\", \"Mutation_Count\", \"Mutations\"]])\n",
    "\n",
    "# ç»Ÿè®¡æœ€çƒ­é—¨çš„çªå˜\n",
    "all_muts = []\n",
    "for m_str in df_results[\"Mutations\"]:\n",
    "    if m_str:\n",
    "        all_muts.extend(m_str.split(\", \"))\n",
    "\n",
    "if all_muts:\n",
    "    from collections import Counter\n",
    "    counts = Counter(all_muts)\n",
    "    print(\"\\nğŸ”¥ [Hotspots] å‡ºç°é¢‘ç‡æœ€é«˜çš„çªå˜ (å…±è¯†çªå˜):\")\n",
    "    for mut, count in counts.most_common(10):\n",
    "        print(f\"   {mut}: å‡ºç° {count}/{NUM_CHAINS} æ¬¡\")\n",
    "else:\n",
    "    print(\"\\næ²¡æœ‰å‘ç”Ÿä»»ä½•çªå˜ï¼Œè¯·æ£€æŸ¥ MASK_RATIO æ˜¯å¦å¤ªä½æˆ– TOP_K æ˜¯å¦ä¸º 1ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ä¿å­˜ç»“æœ\n",
    "å°†ç”Ÿæˆçš„åºåˆ—ä¿å­˜åˆ° Excel æ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿åç»­è¿›è¡Œç»“æ„éªŒè¯ (AlphaFold) æˆ–å®éªŒç­›é€‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"evolved_variants.xlsx\"\n",
    "df_results.to_excel(output_file, index=False)\n",
    "print(f\"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_file}\")\n",
    "print(\"å»ºè®®ä¸‹ä¸€æ­¥ï¼š\")\n",
    "print(\"1. å°†ç”Ÿæˆçš„åºåˆ—è¾“å…¥ AlphaFold/ESMFold é¢„æµ‹ç»“æ„ã€‚\")\n",
    "print(\"2. å‰”é™¤ pLDDT åˆ†æ•°æ˜¾è‘—é™ä½çš„åºåˆ—ã€‚\")\n",
    "print(\"3. é‡ç‚¹å…³æ³¨ 'å…±è¯†çªå˜' (Hotspots)ï¼Œè¿™äº›é€šå¸¸æ˜¯ LoRA æ¨¡å‹æœ€ç¡®å®šçš„ä¼˜åŒ–ç‚¹ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
